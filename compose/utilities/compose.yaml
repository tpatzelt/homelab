services:
  # librespeed:
  #   container_name: librespeed
  #   image: ghcr.io/librespeed/speedtest:latest
  #   restart: unless-stopped
  #   environment:
  #     MODE: standalone
  #   ports:
  #     - 8001:8080
  #   volumes:
  #     - /opt/dockerdata/librespeed:/database

  # yt-dlp-webui:
  #   container_name: yt-dlp-webui
  #   image: ghcr.io/marcopiovanello/yt-dlp-web-ui:latest
  #   restart: unless-stopped
  #   ports:
  #     - 8006:3033
  #   volumes:
  #     - /opt/dockerdata/yt-dlp-webui/downloads:/downloads
  #     - /opt/dockerdata/yt-dlp-webui/config:/config
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:3033"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 3
  karakeep:
    container_name: karakeep
    image: ghcr.io/karakeep-app/karakeep:${KARAKEEP_VERSION:-release}
    restart: unless-stopped
    volumes:
      - /opt/dockerdata/karakeep/data:/data
    ports:
      - 8011:3000
    env_file:
      - .env
    environment:
      MEILI_ADDR: http://karakeep-meilisearch:7700
      BROWSER_WEB_URL: http://karakeep-chrome:9222
      # OPENAI_BASE_URL: http://llama-cpp:8080/v1
      # OPENAI_API_KEY: sk-dummy-key
      # INFERENCE_TEXT_MODEL: Qwen2.5-Omni-3B-BF16.gguf
      # INFERENCE_IMAGE_MODEL: Qwen2.5-Omni-3B-BF16.gguf
      # INFERENCE_JOB_TIMEOUT_SECONDS: 3000
      # INFERENCE_OUTPUT_SCHEMA: plain
      # INFERENCE_ENABLE_AUTO_SUMMARIZATION: true
      DATA_DIR: /data 

  karakeep-chrome:
    container_name: karakeep-chrome 
    image: gcr.io/zenika-hub/alpine-chrome:124
    restart: unless-stopped
    command:
      - --no-sandbox
      - --disable-gpu
      - --disable-dev-shm-usage
      - --remote-debugging-address=0.0.0.0
      - --remote-debugging-port=9222
      - --hide-scrollbars

  karakeep-meilisearch:
    container_name: karakeep-meilisearch
    image: getmeili/meilisearch:v1.13.3
    restart: unless-stopped
    env_file:
      - .env
    environment:
      MEILI_NO_ANALYTICS: "true"
      MEILI_MASTER_KEY: ${MEILI_MASTER_KEY}
    volumes:
      - /opt/dockerdata/karakeep/meilisearch:/meili_data

  # llama-cpp:
  #   container_name: llama-cpp
  #   image: ghcr.io/ggml-org/llama.cpp:server
  #   restart: unless-stopped
  #   command: >
  #     -m /models/Qwen2.5-Omni-3B-BF16.gguf --port 8080 --host 0.0.0.0 -n 512
  #   ports:
  #     - 8018:8080
  #   volumes:
  #     - /mnt/storage/vllm-models:/models
